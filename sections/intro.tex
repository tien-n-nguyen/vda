\section{Introduction}
\label{intro:sec}

%The need for cyber resilience is increasingly important in our~techno\-logy-dependent society, where software systems have been, and will continue to be the target of cyber attackers. 
Software Vulnerabilities (SVs) are security weaknesses and flaws that
are exploitable in the cyber-attacks. New software security
vulnerabilities are discovered on an almost daily basis. It is crucial
to identify software vulnerabilities as early as possible, because
late corrections of errors could cost much more than early correction
or even cause more severe damage. Recognizing this, researchers
propose the approaches to detect software vulnerabilities as soon as
new code changes are committed to the code repositories during
software development. Those approaches are referred to as {\em
  commit-level vulnerability detection
  (VD)}~\cite{perl2015vccfinder,zhou2017automated,chen2019large}. They
could be used to warn developers early on potential vulnerable code.

For potential vulnerable code, it would be also useful to provide
developers with the assessment on the impacts and severity of the
vulnerability on the system under development. In the Common
Vulnerability Scoring System (CVSS)~\cite{first-website}, the security
experts and analysts have manually provided the assessments in terms
of numerical ratings to quantify different aspects of a software
vulnerability including the exploitability, the impacts and the
severity of the attacks, the level of damages of the vulnerabilities,
etc (Figure~\ref{CVSS-tab}). The numerical scores can be translated
into qualitative representations (such as low, medium, high, and
critical) to help organizations properly assess and prioritize their
vulnerability management processes~\cite{first-website}. Despite its
usefulness, there are restrictions. First, human efforts are needed
for the {\em manual assessment}, leading to the delays in the process.
Second, CVSS scores are provided {\em after} a vulnerability was
reported. Therefore, for an early action, the {\em automated,
  commit-level vulnerability assessment} is desired. The VD and
assessment tools can be integrated into the code repositories to
provide just-in-time assistance.

%Several frameworks have been proposed to provide assessments on
%software vulnerabilities, which aim to quantify the exploitability,
%the impacts and the severity of the attacks, the level of damages in
%access control, etc.  For example, the Common Vulnerability Scoring
%System (CVSS)~\cite{first-website} captures the principal
%characteristics of a vulnerability and produces a numerical score and
%ratings reflecting the different aspects of a software vulnerability
%(Fig.~\ref{CVSS-tab}). The numerical score can then be translated into
%a qualitative representation (such as low, medium, high, and critical)
%to help organizations properly assess and prioritize their
%vulnerability management processes~\cite{first-website}.

%
%While it is urgent to have a quick assessment of the vulnerabilities,
%there is often the delay in the manual process of assigning the CVSS
%grades to the new software vulnerability (SV) by security
%analysts~\cite{feutrill-candar18,meneely-esem13}.  Le {\em et
%  al.}~\cite{deepCVA-ase21} have reported that there were 1,165 days,
%on average, from when an SV was injected in a codebase until its
%report was published on National Vulnerability Database (NVD). Delay
%in the assessment of SVs might cause serious consequences due to the
%unknown impacts of the SVs on the attacked systems.

Le {\em et al.}~\cite{deepCVA-ase21} proposed DeepCVA, the
state-of-the-art, commit-level software vulnerability assessment tool
operating on the code changes that were committed to the repository.
%Tien
%and detected as potential vulnerable by a vulnerability detection
%tool.
The authors have leveraged the aforementioned CVSS ratings manually
assessed by security analysts for the vulnerabilities as labeled data
to train a machine learning (ML) model and applied it on the committed
code change to predict the assessment ratings.
%trained their machine learning (ML) model with the
%ratings manually assessed by the security analysts for the
%vulnerabilities from CVSS and applied the model on the committed code
%change to predict the rating estimations.
%
%DeepCVA has shown that the features from vulnerability-introducing
%code changes w.r.t. the current project can help a machine learning
%model to predict the CVSS grades for the SV.
DeepCVA extracts $n$-grams ($n$=1,3,5) from the commits and related
code and uses convolutional gated recurrent units~\cite{fu2016using}
to learn over $n$-grams to predict assessment ratings, simultaneously
using multi-task learning. 

%Tien
%To help security analysts in the assessment, several approaches have
%been proposed to automate the
%process~\cite{lamkanfi-msr10,han-icsme17,SPANOS-jss18,le-msr19}.
%Those approaches operate on bug reports and software~vulnerability
%reports after a vulnerability was detected and~filed~into a
%vulnerablity database. Le {\em et al.}~\cite{deepCVA-ase21} recently
%proposed Deep\-CVA, the state-of-the-art, commit-level software
%vulnerability (SV) assessment tool operating on the code changes that
%were committed to the repository and detected as a vulnerability by a
%vulnerability detection (VD) tool. This type of commit-level
%vulnerability assessment is useful for developers during the coding
%process.  When they make a commit to the code repository, a VD tool
%can be used to decide if the commit is vulnerability-contributing in
%the current project. If a vulnerability is detected, such an SV
%assessment tool can be used to obtain an estimation of the assessment
%on the potential impacts of the vulnerability. That is, the VD and SV
%assessment tools can be integrated into the code repositories to
%provide just-in-time detection and assessment of potential
%vulnerabilities.


%works directly on the committed code changes deemed to contain
%a vulnerability, and produces the CVSS grades for the SV.

%DeepCVA has shown that the features from vulnerability-introducing
%code changes w.r.t. the current project can help a machine learning
%model to predict the CVSS grades for the SV. DeepCVA extracts
%$n$-grams ($n$=1,3,5) from the commits and related code and uses
%convolutional gated recurrent units~\cite{fu2016using} to learn over
%$n$-grams to predict assessment grades, simultaneously using
%multi-task learning. Despite being first to tackle commit-level SV
%assessment, it still suffers low~accuracy.

%The state-of-the-art model
Despite being first to tackle commit-level SV assessment,
DeepCVA~\cite{deepCVA-ase21} still suffers low~accuracy.  In general,
it has three main drawbacks.  First, DeepCVA has limitation on {\bf
  its representations of code changes} and surrounding
code. Specifically, $n$-grams are insufficient to capture the
execution flows among code elements surrounding the changes. {\em The
  important statements having dependencies with the changed statements
  can be useful for the assessment, but can be far apart}. For
example, many Denial of Service (DoS) vulnerabilities are related to
null-pointer exceptions, exception flows, segmentation faults,
etc. The execution flows among statements are not well-represented via
$n$-grams with such limited lengths. Moreover, {\em the statements in
  an $n$-gram might be irrelevant to the current vulnerability}. Thus,
the assessment of a DoS vulnerability with $n$-grams could be
imprecise. {\em $n$-grams also enforce an order in source code}, which
might not be the execution order, e.g., in the cases of loop,
condition, or recursion. The execution order and dependencies among
the statements are important in an DoS. Thus, to assess the impact of
%a DoS, or a general impact of
a vulnerability, $n$-gram is limited.

Second, to estimate the impacts of an SV, a model
needs to consider {\bf program dependencies} among statements since an
attack to a vulnerability involves the~exploits of the control and
data dependencies. DeepCVA captures code changes as code tokens in
short sequences with $n$-grams, thus, does not model the program flows
and dependencies. Finally, it does not represent well the {\bf code
  context} surrounding a change. The same change occurring in
different contexts might cause different effects, leading to different
impact grades. In DeepCVA~\cite{deepCVA-ase21}, the context of
un-changed code is not~distinguishable and not explicitly represented
separately from~the code changes. The model can be confused in
training by the two instances having the same combination of code
changes and contexts, but with different code changes and
contexts themselves.

%Technical paras

We present {\tool}, a Context-aware, Graph-based, Commit-level
Vulnerability Detection and Assessment Model to evaluate a changed
code, detect any vulnerability and provide the CVSS
assessment grades for the detected vulnerability. To build {\tool}, we
provide a novel integration among three key ideas. First, to make
prediction on the CVSS assessment grades on code changes, we develop a
novel {\bf context-aware, graph-based, representation learning (RL)
  model} to {\bf learn the contextualized embeddings for the code
  changes} that integrate {\em program dependencies}, and the
surrounding {\em contexts} of code changes.  Both versions of the
program dependence graphs (PDGs) before and after the commit are
modeled via the multi-version {\mvpdg}~\cite{flexeme-fse20},
built from the PDGs before and after the changes.
%{\mvpdg} is a directed graph generated from the disjoint union of all
%nodes and edges in the PDGs at the versions before and after the
%changes.
To build such embeddings for code changes, {\tool} {\em explicitly
  represents the contexts} surrounding the changed statements via the
sub-graphs in {\mvpdg}. It considers the impact of the surrounding
context represented by a context vector on the building of the
embeddings for the code changes. {\tool} uses the contextualized
embeddings to predict if the changes have any vulnerability, and if
yes, it provides the CVSS assessment grades for it.

Second, we use the Label, Graph Convolution
Network~\cite{label-gcn} to encode the {\bf program dependencies}
among the entities in the changed code and the ones in the
surrounding un-changed code. This helps overcome the issues
with $n$-grams and capture the statements that might be far
apart but are relevant to the vulnerability.

Third, the detection and assessments of different aspects of a
vulnerability are interdependent on each other, e.g., between the
availability and integrity of a system. During the assessment of one
aspect, we also consider the impacts of the other aspects by
leveraging a {\bf multi-task learning} model to propagate the learning
from one task to another (each task learns to assess one
aspect). Vulnerabiity detection is one task in the multi-task learning
as {\tool} will provide assessment scores when a vulnerability is
detected.
%the assessment scores make sense if the detection result is positive.

%Experimental results
We have conducted experiments to evaluate {\tool} on real-world
vulnerabilities. Our results on a C dataset with 7.8k vulnerabilities
show that {\tool} achieves F-score of 25.5\% and MCC of 26.9\%
relatively higher than DeepCVA~\cite{deepCVA-ase21}.  The
vulnerability detection result from {\tool} is also improved over the
state-of-the-art ML/DL-based approaches from from 13-–29.6\% in
precision, 15.6-–28.9\% in recall, and 16.4–-25.8\% in F-score. The
results on a Java dataset with 1,229 vulnerabilities show that {\tool}
achieves F-score of 20.4\% and MCC of 28.0\% relatively higher than
DeepCVA~\cite{deepCVA-ase21}.

%Our sensitivity analysis shows that all designed components in {\tool}
%contribute positively to its high accuracy.

For the insights, we conducted experiments to show that the
higher~accuracy of {\tool} over DeepCVA roots from~our designed
components.
%We also conducted experiments to show that the higher~accuracy of
%{\tool} over DeepCVA comes from our designed~components.
Our results show that {\em our novel code change embeddings} help
{\tool} better in classifying the commits into the classes for
vulnerability assessment than DeepCVA. Moreover, we used an {\em
  explainable AI tool} to show that {\tool} indeed leverages the key
features in {\em program dependencies} for its correct
assessments.

The key contributions of this work include

{\bf 1. {\tool}: commit-level, context-aware, graph-based, 
  vulnerability assessment model} overcomes the issues in the
existing model in $n$-gram representations of dependencies and
contexts.

{\bf 2. Our novel context-aware, graph-based embeddings for code
  changes}
%Our {\em contextualized embeddings for code changes}
integrate dependencies and contexts. This embedding model
is applicable for other down-stream tasks.


{\bf 3. Empirical evaluation.} We evaluated {\tool} 
against the state-of-the-art approach.
Our tool/data are available at~\cite{cat-website}.

