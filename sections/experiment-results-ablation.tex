\subsubsection{\bf Ablation Study (RQ5)}

\input{sections/multi-task-table}

%		   \tool w/o Multi-task Learning       & 0.68  &  0.52    & 0.25         \\
%                    \tool with (VD $\rightarrow$ VA)   &  0.68      &   0.36   &  0.18  \\    
%                    \tool w/o Context                 & 0.75 &  0.57    & 0.29         \\

As seen in Table~\ref{RQ4-result-1}, without multi-task learning, the
performance decreases 13\% F-score in detection and 16\% macro F-score
in assessment. Without context, it decreases 11.6\% F-score in
detection and 10.9\% macro F-score in assessment. We also built the
model (VD $\rightarrow$ VA) in which the detection classifier is used
first, and the assessment classifier is then used if the detection
outcome is positive. Table~\ref{RQ4-result-1} confirms our
hypotheses:

(1) Multi-task learning helps improve both vulnerability detection and
assessment: adding multi-task learning, both VD and VA improve (0.71
to 0.81, 0.54 to 0.64). Note: without multi-task learning, {\tool}
also improves over the baselines (Tables~\ref{tab:rq1}--~\ref{rq1_results}) in both VD and VA due to {\tool}'s better code
change embeddings (Section~\ref{sec:separation}).

(2) Multi-task learning model performs much better than
(VD $\rightarrow$ VA), which has the cascading error due to
false positives in VD.

(3) both multi-task learning and context have positive contributions,
in which multi-task learning contributes more.

%The corresponding decrease values for the model without Context are
%11.6\% F-score in detection and 10.9\% macro F-score in
%assessment. Thus, multi-task learning contributes more than
%context. We also built a model in which the detection classifier is
%applied first and if the result is positive (e.g., vulnerability), the
%classifiers for assessment will be used (i.e., VD $\rightarrow$ VA).
%As seen, the cascading error due to false positives reduce the
%performance significantly.



%As seen in Table~\ref{RQ4-result-1}, without~the context, the macro
%F-score and multi-class MCC decrease by 4.7\% and 6.1\%, respectively.
%Without the multi-task learning, the macro F-score and multi-class MCC
%decrease by 6.3\% and 9.1\%, respectively. While both the context and
%multi-task learning play positive roles in {\tool}'s accuracy,
%multi-task learning contributes slightly more.


%Table~\ref{RQ4-result-1} shows the overall macro-F-score and multi-class MCC results when the key features in {\tool} were removed. As seen in Table~\ref{RQ4-result-1}, without the context vector, the macro-F-score and multi-class MCC decrease by 4.7\% and 6.1\%, respectively. And without the multi-tasking framework, the macro-F-score and multi-class MCC decrease by 6.3\% and 9.1\%, respectively. While both context vector and the multi-tasking framework play a positive role in the overall performance, the multi-tasking framework contributes more to {\tool}.

\begin{table}[t]
	\caption{RQ5. Impact of Num. of Hops $k$ for Context Size}
	\vspace{-10pt}
	\begin{center}
%		\scriptsize
\small
		\tabcolsep 4pt
		\renewcommand{\arraystretch}{1} \begin{tabular}{p{3.5cm}<{\centering}|p{2cm}<{\centering}p{1.2cm}<{\centering}}
			
			\hline
			& macro F-Score & MCC \\ 
			\hline
			\tool ($k=1$)          & 0.62 & 0.32          \\
			\tool ($k=2$)          & 0.63 & 0.33          \\
			\tool ($k=3$)          & 0.64 & 0.33          \\
			\tool ($k=4$)          & 0.62 & 0.31          \\
			\tool ($k=5$)          & 0.61 & 0.30          \\
			\hline
		\end{tabular}
		\label{RQ4-result-2}
	\end{center}
\end{table}

Table~\ref{RQ4-result-2} shows the impact of the context size $k$ (the
number of hops from a changed node). As seen, when
%the context size
$k$ increases from 1--3, the macro F-score increases to its highest
value of 0.64.
%and the multi-class MCC increases to its highest value of 0.33.
However, when $k$ continues to increase $k \geq 3$, both macro F-score
and multi-class MCC decrease. The rationale is that as the context
size is too small, the limited number of surrounding nodes cannot
capture well the relevant statements for assessment. As the context size gets larger, the
increasing number of the irrelevant statements will bring in
biases. Thus, we selected $k$=3 in
other studies on the C dataset.

%Table~\ref{RQ4-result-2} shows the overall macro-F-score and multi-class MCC when we evaluate the size $K$ of a context (i.e., the number of hops from the changed node) on the C dataset. From the table, we can see that when the number of hops from the changed node increase from $K=1$ to $K=3$, the macro-F-score increases to its highest value $0.64$ and the multi-class MCC increases to its highest value $0.33$. But after $K=3$, with the rise of $K$ value, both macro-F-score and multi-class MCC decrease. The reason that causes this is that when the $K$ value is too small, the limited amount of surrounding nodes cannot capture all the relevant nodes well for \tool to learn the context information well. But if the $K$ value is too big, the increasing number of the irrelevant nodes will bring in too many biases and hurt the overall performance of \tool. Therefore, we select $K=3$ to be the best setting for \tool on our C dataset with this analysis.  















\iffalse

\begin{table}[h]
	\caption{Sensitive Analysis -- Impact of Different Factors on {\tool}'s Accuracy in terms of Top1 on BigFix Dataset. 
	%	Seq2seq: Simple Sequence to Sequence model; Two-Layer-EDM: Two Layers Tree-Based LSTM Encoder-Decoder Model; PAT: Program Analysis Techniques including Renaming and Program Analysis Filters.
	}
	\vspace{-10pt}
	\begin{center}
		\renewcommand{\arraystretch}{1} 
		\begin{tabular}{l|p{0.7cm}<{\centering}|p{1.5cm}<{\centering}}
			\hline
			Models & Top1 & Improvement\\
			\hline
			Seq2Seq & 1.8\% & \\
			Seq2Seq + PAT & 6.4\% & 256\% \\ 
			Two-Layer-EDM & 11.7\% & 550\%\\
			Two-Layer-EDM + PAT &  24.4\% &109\%\\
			Two-Layer-EDM + PAT + Re-ranking & 29.4\%&20.5\% \\
			\hline
		\end{tabular}
	Seq2seq: a simple sequence-to-sequence model; Two-Layer-EDM: Two-layer tree-based LSTM encoder-decoder model; 
	PAT: program analysis (PA) Techniques including Renaming and PA Filters.
		\label{RQ3}
	\end{center}
%\vspace{-10pt}
\end{table}

%We conducted an experiment to study how different factors including renaming, two Layer encoder-decoder model, models for encoders and decoders, program analysis filters, re-selecting model affect our model's accuracy.

Table~\ref{RQ3} shows that we build three variants of {\tool} with
different factors and their combinations.  We analyze our results as
follows:

(1) \textbf{Impact of Two-Layer-EDM}. Our Two-Layer-EDM
can improve the one-layer sequence-to-sequence model by 550\% and
using only {\em seq2seq} cannot get good results. Two-layer-EDM is
designed to learn the local context of a bug fix and code
transformations.

(2) \textbf{Impact of PAT}. Using program analysis (PA) techniques,
PAT, including alpha-renaming and PA-filtering, is effective to
improve Two-Layer-EDM by 109\%.
%This is reasonable because the program analysis techniques can make our data become more common in order to make the training data can contribute more and also can help reduce the wrong candidate patch by program analysis filters to reduce the search space and increase the accuracy.
The alpha-renaming process can help improve {\tool} for better training
and the PA-filtering process can help elminate more the irrelevant patches.
%From \textit{Seq2seq} in Table~\ref{RQ3}, we can see that by only using one layer simple seq2seq model to do the bug fix cannot get a good result on BigFix.
%To study the impact of our two layers tree-based encoder decoder model, we compare the results obtained from two variants: \textit{Seq2seq} and \textit{TLTM}. The results show that using the our two layers tree-based encoder decoder model can increase accuracy relatively by 550\%. This is because TLTM can analysis local context and code transformation at the same time with less biases.

Adding program analysis to the basic {\em seq2seq} model can improve
it by 256\%. However, the Two-Layer-EDM can improve seq2seq by 550\%.
Thus, the Two-Layer-EDM has more impact than PAT.

(3) \textbf{Impact of Re-ranking}. The results
of \textit{Two-Layer-EDM + PAT + Re-Ranking} show that having
re-ranking can increase accuracy relatively by 20.5\%. The reason is
that the re-ranking process, which uses a Convolutional Layer to
distinguish the best result from the others, can help increase
{\tool}'s accuracy by pushing the right results to the top of the list
of the candidate fixes.

\fi

%The re-ranking part which uses convolutional layer to classify the
%best result and other results can help increase the accuracy of our
%approach. In this way, the re-ranking can help our approach a lot.
%The Re-ranking can improve the model with Two-layer-EDM + PAT by
%20.5\%. The results show that once the model generates a list of
%candidate patches, re-ranking the list can help improve the results.
